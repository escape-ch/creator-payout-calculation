{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parameters\n",
    "- **APP_ID**: id of the app in the database\n",
    "- **START_DATE**: Start of the analysis period (inclusive); all metrics are computed from this date onward.\n",
    "- **END_DATE**: End of the analysis period (exclusive); no data beyond this date is considered.\n",
    "- **FREQ**: Time aggregation frequency (e.g. daily, every 3 days, or weekly); affects smoothing and compounding of metrics.\n",
    "    - used in pandas.resample(freq= FREQ)\n",
    "- **TARGET_COUNTRY**: Limits the analysis to traffic and revenue originating from this country.\n",
    "- **VIEWS_THRESHOLD**: Threshold for views after which an account should be considered in the model\n",
    "\n",
    "- **DIMINISHING_RETURNS**: Controls how strongly marginal returns decay as volume increases; higher values imply stronger saturation effects.\n",
    "    - 1 => full effect\n",
    "    - 0 => no effect\n",
    "\n",
    "- **PROCEEDS_PERCENTAGE_FOR_ATTRIBUTION**: Fraction of total proceeds eligible for attribution to the modeled channel.\n",
    "- **ASSUMED_ROI**: Expected return on investment used to define the payouts.\n",
    "    - PAYOUT = ATTRIBUTED_PROCEEDS/ASSUMED_ROI\n",
    "- **RPM_CAP**: Maximum allowed revenue per 1,000 impressions to prevent unrealistically high revenue estimates.\n"
   ],
   "id": "8da4eebafbdb53af"
  },
  {
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "cell_type": "code",
   "source": [
    "APP_ID = 1\n",
    "TIME_WINDOW = '30d'\n",
    "FREQ = \"D\"  ## or \"D\" for daily or  \"3D\" 3 daily, \"W-Mon\"\n",
    "TARGET_COUNTRY = \"United_States\"\n",
    "VIEWS_THRESHOLD = 100\n",
    "\n",
    "DIMINISHING_RETURNS = 0.9  ## 0-1: 0 no diminishing returns 1 full diminishing returns\n",
    "\n",
    "DEFAULT_RPM = 3 ## rpm we are paying to creators used as a base, currently 2$\n",
    "PROCEEDS_PERCENTAGE_FOR_ATTRIBUTION = 0.8\n",
    "ASSUMED_ROI = 3  ## ROI assumed for payout computation\n",
    "RPM_CAP = 4  ## max rpm allowed\n",
    "\n",
    "print(f\"\"\"\n",
    "APP_ID: {APP_ID}\n",
    "TIME_WINDOW: {TIME_WINDOW}\n",
    "FREQ: {FREQ}\n",
    "TARGET_COUNTRY: {TARGET_COUNTRY}\n",
    "VIEWS_THRESHOLD: {VIEWS_THRESHOLD}\n",
    "\n",
    "DIMINISHING_RETURNS: {DIMINISHING_RETURNS}\n",
    "\n",
    "DEFAULT_RPM: {DEFAULT_RPM}\n",
    "PROCEEDS_PERCENTAGE_FOR_ATTRIBUTION: {PROCEEDS_PERCENTAGE_FOR_ATTRIBUTION}\n",
    "ASSUMED_ROI: {ASSUMED_ROI}\n",
    "RPM_CAP: {RPM_CAP}\n",
    "\"\"\")"
   ],
   "id": "963991de8cb91e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "# Do all imports\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import os\n",
    "\n",
    "PWD = os.getcwd()\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, PWD + './transformations.py')\n",
    "sys.path.insert(1, PWD + './helpers.py')\n",
    "\n",
    "from transformations import Winsorizer, FeatureMultiplier, Average\n",
    "from helpers import logistic_map\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "PWD\n"
   ],
   "id": "590aa8d336105371",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# define engagement factor rates\n",
    "engagement_factor_weights = {\n",
    "    \"likes_rate\": 1,\n",
    "    \"comments_rate\": 1.2,\n",
    "    \"saves_rate\": 0.5,\n",
    "    \"shares_rate\": 0,\n",
    "    \"likes_to_comments\": 1,\n",
    "}\n",
    "\n",
    "# engagement volume weights\n",
    "engagement_volume_weights = {\n",
    "    \"views\": 0.8,\n",
    "    \"likes\": 1,\n",
    "    \"comments\": 1.2,\n",
    "    \"saves\": 0.3,\n",
    "    \"shares\": 0.3,\n",
    "}\n",
    "\n",
    "# other configuration variables\n",
    "vol_cut_ranges = [0, 1000, 10_000, 100_000, 1_000_000, np.inf]\n",
    "\n",
    "# %-+ allowed incentive boost\n",
    "incentive_boost_effect = 0.2\n",
    "# how curved or linear incentive boost should be, less is more linear\n",
    "incentive_boost_order = 2"
   ],
   "id": "98a685938d89d351",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Data",
   "id": "7f0b21e438b14790"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "views_shifted_before_date = pd.Timestamp('2025-12-01')\n",
    "\n",
    "df_revenue = (\n",
    "    pd\n",
    "    .read_sql_query(\n",
    "        sql=\"\"\"\n",
    "            select\n",
    "                s.date,\n",
    "                s.country,\n",
    "                sum(s.proceeds) / 100.0 as proceeds\n",
    "            from superwall_metrics s\n",
    "            where\n",
    "                s.app_id = %(APP_ID)s\n",
    "                and s.date >= CURRENT_DATE - INTERVAL %(TIME_WINDOW)s\n",
    "                and country in (%(TARGET_COUNTRY)s, 'United_Kingdom')\n",
    "\n",
    "            group by s.date, s.country\n",
    "            having sum(s.proceeds) > 0\n",
    "        \"\"\",\n",
    "        con=os.getenv(\"DATABASE_URL\"),\n",
    "        params={\n",
    "            \"APP_ID\": APP_ID,\n",
    "            \"TIME_WINDOW\": TIME_WINDOW,\n",
    "            \"TARGET_COUNTRY\": TARGET_COUNTRY\n",
    "        },\n",
    "        parse_dates=['date']\n",
    "    )\n",
    "    .assign(\n",
    "        date=lambda x: x.date + pd.Timedelta(days=1) * (x.date < views_shifted_before_date),\n",
    "        country=lambda x: x.country.map({\"United_Kingdom\": \"United_States\"}).fillna(x.country)\n",
    "    )\n",
    ")"
   ],
   "id": "d096086de322a7eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stat_cols = [\n",
    "    \"views_diff\",\n",
    "    \"likes_diff\",\n",
    "    \"comments_diff\",\n",
    "    \"saves_diff\",\n",
    "    \"shares_diff\"\n",
    "]\n",
    "\n",
    "df_scrape_data = (\n",
    "    pd\n",
    "    .read_sql_query(\n",
    "        sql=\"\"\"\n",
    "            select\n",
    "                sma.date,\n",
    "                sma.id as account_id,\n",
    "                sma.campaign_id as campaign_id,\n",
    "                sma.country as account_country,\n",
    "                sma.total_views_diff as views_diff,\n",
    "                sma.total_likes_diff as likes_diff,\n",
    "                sma.total_comments_diff as comments_diff,\n",
    "                sma.total_saves_diff as saves_diff,\n",
    "                sma.total_shares_diff as shares_diff,\n",
    "                sma.total_posts_diff as posts_diff\n",
    "            from social_media_accounts_daily_diff sma\n",
    "            where\n",
    "                sma.date >= CURRENT_DATE - INTERVAL %(TIME_WINDOW)s\n",
    "                and total_views_diff > %(VIEWS_THRESHOLD)s\n",
    "                and total_views_diff > sma.total_likes_diff\n",
    "                and sma.country = %(TARGET_COUNTRY)s\n",
    "            order by sma.date desc\n",
    "        \"\"\",\n",
    "        con=os.getenv(\"DATABASE_URL\"),\n",
    "        params={\n",
    "            \"TIME_WINDOW\": TIME_WINDOW,\n",
    "            \"VIEWS_THRESHOLD\": VIEWS_THRESHOLD,\n",
    "            \"TARGET_COUNTRY\": TARGET_COUNTRY\n",
    "        },\n",
    "        parse_dates=['date']\n",
    "    )\n",
    "\n",
    ")\n",
    "df_scrape_data[stat_cols] = df_scrape_data[stat_cols].clip(0, np.inf)"
   ],
   "id": "fed63c1c89f01fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data prep",
   "id": "4d961f144bdc2a90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def add_aggregate_metrics(df):\n",
    "    df = (\n",
    "        df\n",
    "        .assign(\n",
    "            likes_rate=lambda x: x['likes_diff'] / x[\"views_diff\"],\n",
    "            comments_rate=lambda x: x['comments_diff'] / x[\"views_diff\"],\n",
    "            saves_rate=lambda x: x['saves_diff'] / x[\"views_diff\"],\n",
    "            shares_rate=lambda x: x['shares_diff'] / x[\"views_diff\"],\n",
    "            likes_to_comments=lambda x: (x['comments_diff'] / x[\"likes_diff\"]).clip(0, 1),\n",
    "        )\n",
    "    )\n",
    "    return df"
   ],
   "id": "d7c2d2ec1a0d83cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# aggregate to get account level metrics per date\n",
    "df_posts_model = (\n",
    "    df_scrape_data\n",
    "    .pipe(lambda d: add_aggregate_metrics(d))\n",
    "    .sort_values(\"likes_rate\")\n",
    "    .dropna()\n",
    "    .groupby([\n",
    "        pd.Grouper(key=\"date\", freq=FREQ, label=\"left\", closed=\"left\"),\n",
    "        \"account_id\",\n",
    "        \"campaign_id\",\n",
    "        \"account_country\",\n",
    "    ], as_index=False)\n",
    "    # .resample(FREQ, on  = \"date\", label = \"left\", closed = 'left')\n",
    "    .agg({v: \"sum\" for _, v in enumerate(stat_cols)})\n",
    "    .pipe(lambda x: add_aggregate_metrics(x).fillna(0))\n",
    ")\n",
    "\n",
    "df_revenue_model = (\n",
    "    df_revenue\n",
    "    .groupby([\n",
    "        pd.Grouper(key=\"date\", freq=FREQ, label=\"left\", closed=\"left\"),\n",
    "        \"country\"\n",
    "    ])\n",
    "    .agg({\n",
    "        \"proceeds\": \"sum\"\n",
    "    })\n",
    "    .reset_index()\n",
    ")"
   ],
   "id": "65cceeeb1ee461c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Computation\n",
    "\n",
    "#### Engagement Factor / Diminishing Returns\n",
    "\n",
    "  - Weighted average of engagements rates (e. g. likes/views, comments/views, comments/likes etc.)\n",
    "  - Because of its negative correlation with views, we can use this as a diminishing returns proxy"
   ],
   "id": "f0239a27d4c76c66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_engagement_factor(rates, weights):\n",
    "    pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"weights\", FeatureMultiplier(weights)),\n",
    "        (\"average\", Average()),\n",
    "        (\"winsor\", Winsorizer(lower_quantile=0.03, upper_quantile=0.99)),  ## clip extremes\n",
    "        (\"minmax\", MinMaxScaler(feature_range=(0, 1)))  # scale to 0-1\n",
    "    ])\n",
    "\n",
    "    return pipeline.fit_transform(rates)\n",
    "\n",
    "engagement_factor_weights_series = pd.Series(engagement_factor_weights)\n",
    "\n",
    "df_posts_model[\"engagement_factor_raw\"] = compute_engagement_factor(\n",
    "    rates=df_posts_model[[\"likes_rate\", \"comments_rate\", \"saves_rate\", \"shares_rate\", \"likes_to_comments\"]].clip(0, 1),\n",
    "    weights=engagement_factor_weights_series,\n",
    ")\n",
    "\n",
    "df_posts_model[\"engagement_factor\"] = (\n",
    "        df_posts_model[\"engagement_factor_raw\"] ** DIMINISHING_RETURNS\n",
    ")"
   ],
   "id": "9d63a66ebf94d5c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# scatter_plot(\n",
    "#     df_posts_model.query(\"engagement_factor > 0\").assign(views_log = lambda x: np.log(x.views_diff+1)),\n",
    "#     \"views_log\",\n",
    "#     \"engagement_factor\",\n",
    "#     xlabel = \"views_log\",\n",
    "#     ylabel = \"engagement_factor\",\n",
    "#     title = \"Log Views vs. Engagement Factor\"\n",
    "# )"
   ],
   "id": "2c8273bf1bef42c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Incentive boost\n",
    "\n",
    "- Statistical transformation on the engagement_factor\n",
    "    - boxcox to make the distribution near normal\n",
    "    - abs max scaling\n",
    "    - stratified normalization --> to make every number comparable for ranking\n",
    "    - logistic mapping for incentive multiplier\n",
    "- here how it works:\n",
    "    - mean performance is 1\n",
    "    - the output is in 0.8 to 1.2\n",
    "      - if above mean ==> max 20% boost (1.2)\n",
    "      - if belov mean ==> min 20% deboost (0.8)"
   ],
   "id": "f80a164a702a7cca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_incentive_boost(df, engagement_col, group_col, boxcox_lambda=None):\n",
    "    boost, _ = scipy.stats.boxcox(df[engagement_col] + 1, lmbda=boxcox_lambda)\n",
    "    df = df[[engagement_col, group_col]].copy()\n",
    "\n",
    "    df['boost'] = boost\n",
    "    df['boost'] /= df['boost'].max()\n",
    "    df['boost'] = df['boost'] / df.groupby(group_col, observed=False)['boost'].transform('mean')\n",
    "\n",
    "    return df['boost'].clip(0, 2)\n",
    "\n",
    "\n",
    "df_posts_model[\"vol_cut\"] = pd.cut(df_posts_model['views_diff'], vol_cut_ranges)\n",
    "\n",
    "df_posts_model[\"incentive_boost_raw\"] = compute_incentive_boost(\n",
    "    df=df_posts_model,\n",
    "    engagement_col=\"engagement_factor\",\n",
    "    group_col=\"vol_cut\",\n",
    ")\n",
    "\n",
    "df_posts_model['incentive_boost'] = logistic_map(df_posts_model['incentive_boost_raw'], d=incentive_boost_effect,\n",
    "                                                 k=incentive_boost_order)"
   ],
   "id": "16c9ed6179c956d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# x = np.linspace(0,2,100)\n",
    "# y = logistic_map(x, d=incentive_boost_effect, k=incentive_boost_order)\n",
    "#\n",
    "# fig, ax = plt.subplots(figsize = (12,5))\n",
    "# ax.plot(x, y, ls = \"\", marker = 'o', markersize = 2)"
   ],
   "id": "c311f61c47674330",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# scatter_plot(\n",
    "#     df_posts_model.query(\"engagement_factor > 0\").assign(views_log = lambda x: np.log(x.views_diff+1)),\n",
    "#     \"views_log\",\n",
    "#     \"incentive_boost_raw\",\n",
    "#     xlabel = \"views_log\",\n",
    "#     ylabel = \"incentive_boost\",\n",
    "#     title = \"Log Views vs. Incentive Boost\"\n",
    "# )"
   ],
   "id": "ce9d3b0e94505116",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Engagement Volume\n",
    "\n",
    "  - Weighted average of volume metrics (e. g. views, shares, comments, likes)"
   ],
   "id": "45ebfad15b069eed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_engagement_volume(volumes, weights):\n",
    "    pipeline = Pipeline([\n",
    "        (\"weights\", FeatureMultiplier(weights)),\n",
    "        (\"average\", Average()),\n",
    "        (\"winsor\", Winsorizer(lower_quantile=0, upper_quantile=1)),\n",
    "    ])\n",
    "\n",
    "    return pipeline.fit_transform(volumes)\n",
    "\n",
    "\n",
    "engagement_volume_weights_series = pd.Series(engagement_volume_weights)\n",
    "\n",
    "df_posts_model['engagement_volume'] = compute_engagement_volume(\n",
    "    volumes=(df_posts_model[stat_cols]).pipe(lambda x: x / x.quantile(0.9)).values,\n",
    "    weights=engagement_volume_weights_series\n",
    ")"
   ],
   "id": "1bdd4e3994121ea0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Quality Volume\n",
    "\n",
    "  - Main metric for attribution, defined as:\n",
    "    - engagement_volume * engagement_factor * incentive_boost"
   ],
   "id": "8d4581b866a6cba3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_posts_model[\"quality_volume\"] = (\n",
    "    df_posts_model[\"engagement_volume\"] *\n",
    "    df_posts_model[\"engagement_factor\"] *\n",
    "    df_posts_model[\"incentive_boost\"]\n",
    ")"
   ],
   "id": "c0162ce455443533",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Computing the payout\n",
    "\n",
    "- **attr_revenue_on_view**: Attributed proceeds, if the allocation is made purely on the view percentages.\n",
    "- **attr_revenue_on_quality**: Attributed proceeds, if the allocation is made on the quality volume percentage.\n",
    "- **payout_raw**: Payout if a flat RPM of DEFAULT_RPM is being choosed,\n",
    "- **payout_on_view**: Payout, computed on the attribted proceeds and assumed ROI, if the allocation is made purely on the view percentage.\n",
    "- **payout_on_quality**: Payout, computed on the attribted proceeds and assumed ROI, if the allocation is made on the quality volume percentage.\n",
    "    - payout is capped to the RPM_CAP to prevent unrealistic payouts for small creators"
   ],
   "id": "2ac941b404817c6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def cap_payout_to_rpm(max_rpm, views, payout):\n",
    "    rpm = payout / (views / 1000)\n",
    "    return np.where(rpm < max_rpm, payout, max_rpm * (views / 1000))"
   ],
   "id": "58b514e95a9eee6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_payout = (\n",
    "    df_posts_model\n",
    "    .merge(\n",
    "        df_revenue_model, left_on=[\"date\"], right_on=[\"date\"]\n",
    "    )\n",
    "    .assign(\n",
    "        total_views_on_day=lambda x: x.groupby(\"date\").views_diff.transform('sum'),\n",
    "        view_percentage=lambda x: x['views_diff'] / x.groupby(\"date\").views_diff.transform('sum'),\n",
    "        quality_percentage=lambda x: x['quality_volume'] / x.groupby(\"date\").quality_volume.transform('sum'),\n",
    "        attr_revenue_on_view=lambda x: x.proceeds * PROCEEDS_PERCENTAGE_FOR_ATTRIBUTION * x[\"view_percentage\"],\n",
    "        attr_revenue_on_quality=lambda x: x.proceeds * PROCEEDS_PERCENTAGE_FOR_ATTRIBUTION * x[\"quality_percentage\"],\n",
    "    )\n",
    "    .assign(\n",
    "        payout_raw=lambda x: x.views_diff * DEFAULT_RPM / 1000,\n",
    "        payout_on_view=lambda x: x.attr_revenue_on_view / ASSUMED_ROI,\n",
    "        payout_on_quality=lambda x: cap_payout_to_rpm(RPM_CAP, x.views_diff, x.attr_revenue_on_quality / ASSUMED_ROI),\n",
    "        rpm=lambda x: (x.payout_on_quality / (x.views_diff / 1000)).round(2).fillna(0),\n",
    "        payout_percentage=lambda x: x['payout_on_quality'] / x.groupby(\"date\").payout_on_quality.transform('sum'),\n",
    "    )\n",
    "    .sort_values(\"views_diff\", ascending=False)\n",
    "\n",
    ")"
   ],
   "id": "68ff1e3f433be676",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Summary",
   "id": "6ea6fc37903e9275"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(\n",
    "    df_payout\n",
    "    .query(\"date != '2025-12-01'\")\n",
    "    .query(\"views_diff > 0\")\n",
    "    .groupby(\"vol_cut\", observed=False)\n",
    "    .agg(\n",
    "        {\n",
    "            \"account_id\": \"count\",\n",
    "            \"views_diff\": \"sum\",\n",
    "            \"attr_revenue_on_view\": \"sum\",\n",
    "            \"attr_revenue_on_quality\": \"sum\",\n",
    "        }\n",
    "    )\n",
    "    .assign(\n",
    "        view_perc=lambda x: x.views_diff / x.views_diff.sum(),\n",
    "        attr_perc_on_quality=lambda x: x.attr_revenue_on_quality / x.attr_revenue_on_quality.sum(),\n",
    "        attr_perc_on_view=lambda x: x.attr_revenue_on_view / x.attr_revenue_on_view.sum(),\n",
    "        raw_rpm_payout=lambda x: x.views_diff * 2 / 1000,\n",
    "        avg_payout_rpm_on_view=lambda x: x.attr_revenue_on_view / (x.views_diff / 1000) / ASSUMED_ROI,\n",
    "        avg_payout_rpm_on_quality=lambda x: x.attr_revenue_on_quality / (x.views_diff / 1000) / ASSUMED_ROI,\n",
    "    )\n",
    "    # .to_clipboard()\n",
    ")"
   ],
   "id": "9eb48eb135f290ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Upsert Data to Postgres",
   "id": "c17ceb7d250581e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "INSERT_BATCH_SIZE = 100\n",
    "\n",
    "df_payout = df_payout.assign(\n",
    "    date_str=lambda x: x.date.dt.strftime(\"%Y-%m-%d\"),\n",
    "    vol_cut_str=lambda x: str(x.vol_cut),\n",
    ")\n",
    "\n",
    "# in order\n",
    "payout_insert_cols = {\n",
    "    'date_str': 'date',\n",
    "    'account_id': 'account_id',\n",
    "    'campaign_id': 'campaign_id',\n",
    "    'total_views_on_day': 'total_views_on_day',\n",
    "    'views_diff': 'views_diff',\n",
    "    'likes_diff': 'likes_diff',\n",
    "    'comments_diff': 'comments_diff',\n",
    "    'saves_diff': 'saves_diff',\n",
    "    'shares_diff': 'shares_diff',\n",
    "    'likes_rate': 'likes_rate',\n",
    "    'comments_rate': 'comments_rate',\n",
    "    'saves_rate': 'saves_rate',\n",
    "    'shares_rate': 'shares_rate',\n",
    "    'likes_to_comments': 'likes_to_comments',\n",
    "    'engagement_factor_raw': 'engagement_factor_raw',\n",
    "    'engagement_factor': 'engagement_factor',\n",
    "    'vol_cut_str': 'vol_cut',\n",
    "    'incentive_boost_raw': 'incentive_boost_raw',\n",
    "    'incentive_boost': 'incentive_boost',\n",
    "    'engagement_volume': 'engagement_volume',\n",
    "    'quality_volume': 'quality_volume',\n",
    "    'country': 'country',\n",
    "    'proceeds': 'proceeds',\n",
    "    'view_percentage': 'view_percentage',\n",
    "    'quality_percentage': 'quality_percentage',\n",
    "    'attr_revenue_on_view': 'attr_revenue_on_view',\n",
    "    'attr_revenue_on_quality': 'attr_revenue_on_quality',\n",
    "    'payout_raw': 'payout_raw',\n",
    "    'payout_on_view': 'payout_on_view',\n",
    "    'payout_on_quality': 'payout_on_quality',\n",
    "    'rpm': 'rpm',\n",
    "    'payout_percentage': 'payout_percentage',\n",
    "}\n",
    "\n",
    "upsert_ignore_list = ['date', 'account_id', 'campaign_id']\n",
    "upsert_keys = filter(lambda x: x not in upsert_ignore_list, payout_insert_cols.values())\n",
    "\n",
    "df_payout_reduced = df_payout[payout_insert_cols.keys()]\n",
    "\n",
    "data = list(df_payout_reduced.itertuples(index=False, name=None))\n",
    "UPSERT_COMMA_SEPERATOR = \",\\n\"\n",
    "\n",
    "with psycopg2.connect(os.getenv(\"DATABASE_URL\")) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        insert_query = f\"\"\"\n",
    "            insert into public.account_daily_rpm_calculations ({\", \".join(payout_insert_cols.values())}) values %s\n",
    "            on conflict on constraint account_daily_rpm_calculations_pk do update\n",
    "            set\n",
    "                {UPSERT_COMMA_SEPERATOR.join(list(map(lambda x: f\"{x} = excluded.{x}\",upsert_keys)))},\n",
    "                updated_at = NOW()\n",
    "        \"\"\"\n",
    "        psycopg2.extras.execute_values (\n",
    "            cur, insert_query, data, template=None, page_size=INSERT_BATCH_SIZE\n",
    "        )\n",
    "    conn.commit()\n"
   ],
   "id": "12d97e9def39c799",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
